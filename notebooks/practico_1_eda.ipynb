{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62e24d7",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos - Dataset de Ventas\n",
    "\n",
    "Este notebook contiene el análisis exploratorio completo del dataset de ventas, siguiendo las consignas establecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c990410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Configuración de visualización\n",
    "# plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935672f",
   "metadata": {},
   "source": [
    "## 1. Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f06084",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Carga del dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/sales_data.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Información básica del dataset\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInformación del Dataset:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Santiago Castellanos\\m11-practico1-eda\\m11-practico1-eda\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Santiago Castellanos\\m11-practico1-eda\\m11-practico1-eda\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# Carga del dataset\n",
    "df = pd.read_parquet('data/sales_data.parquet')\n",
    "\n",
    "# Información básica del dataset\n",
    "print(\"Información del Dataset:\")\n",
    "print(\"-----------------------\")\n",
    "print(f\"Dimensiones: {df.shape}\")\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nValores nulos:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c58ab9d",
   "metadata": {},
   "source": [
    "## 2. Limpieza Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de fechas\n",
    "if 'fecha' in df.columns:\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Porcentaje de valores nulos por columna\n",
    "nulos_porcentaje = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Mostrar columnas con valores nulos\n",
    "print(\"Porcentaje de valores nulos por columna:\")\n",
    "print(nulos_porcentaje[nulos_porcentaje > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d67c0",
   "metadata": {},
   "source": [
    "## 3. Análisis Descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60215738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"Estadísticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Análisis de variables categóricas\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"\\nDistribución de {col}:\")\n",
    "    print(df[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c387e4",
   "metadata": {},
   "source": [
    "## 4. Visualizaciones Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8964bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolución temporal de ventas\n",
    "if 'fecha' in df.columns and 'monto' in df.columns:\n",
    "    ventas_diarias = df.groupby('fecha')['monto'].sum().reset_index()\n",
    "    \n",
    "    fig = px.line(ventas_diarias, x='fecha', y='monto',\n",
    "                  title='Evolución temporal de ventas')\n",
    "    fig.show()\n",
    "\n",
    "# Distribución por día de la semana\n",
    "if 'fecha' in df.columns:\n",
    "    df['dia_semana'] = df['fecha'].dt.day_name()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df, x='dia_semana', y='monto')\n",
    "    plt.title('Distribución de ventas por día de la semana')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb2a81",
   "metadata": {},
   "source": [
    "## 5. Análisis de Granularidad Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b941415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de granularidad temporal\n",
    "if 'fecha' in df.columns and 'monto' in df.columns:\n",
    "    # Agrupación diaria\n",
    "    diario = df.groupby('fecha')['monto'].sum()\n",
    "    \n",
    "    # Agrupación semanal\n",
    "    semanal = df.groupby(pd.Grouper(key='fecha', freq='W'))['monto'].sum()\n",
    "    \n",
    "    # Agrupación mensual\n",
    "    mensual = df.groupby(pd.Grouper(key='fecha', freq='M'))['monto'].sum()\n",
    "    \n",
    "    # Visualización comparativa\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    diario.plot(ax=axes[0], title='Ventas Diarias')\n",
    "    semanal.plot(ax=axes[1], title='Ventas Semanales')\n",
    "    mensual.plot(ax=axes[2], title='Ventas Mensuales')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35649c",
   "metadata": {},
   "source": [
    "## 6. Análisis por Punto de Venta y Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top productos por cantidad vendida\n",
    "if 'producto' in df.columns and 'cantidad' in df.columns:\n",
    "    top_productos = df.groupby('producto')['cantidad'].sum().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_productos.plot(kind='bar')\n",
    "    plt.title('Top 10 Productos más Vendidos')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Top puntos de venta por facturación\n",
    "if 'punto_venta' in df.columns and 'monto' in df.columns:\n",
    "    top_pdv = df.groupby('punto_venta')['monto'].sum().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_pdv.plot(kind='bar')\n",
    "    plt.title('Top 10 Puntos de Venta por Facturación')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c61fe",
   "metadata": {},
   "source": [
    "## 7. Hipótesis y Hallazgos\n",
    "\n",
    "[Esta sección se completará con los hallazgos específicos después de ejecutar el análisis con los datos reales]\n",
    "\n",
    "### Respuestas a las preguntas planteadas:\n",
    "\n",
    "1. Dimensiones del dataset: [Se completará]\n",
    "2. Valores faltantes: [Se completará]\n",
    "3. Tipos de variables: [Se completará]\n",
    "4. Columnas redundantes: [Se completará]\n",
    "5. Granularidad: [Se completará]\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
